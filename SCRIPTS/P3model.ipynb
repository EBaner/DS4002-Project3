{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Imports and Setup\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Set device for PyTorch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "E6Q4bKbQpGgJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('HistoricalColor-ECCV2012'):\n",
        "    print(\"Downloading dataset...\")\n",
        "    os.system(\"curl http://graphics.cs.cmu.edu/projects/historicalColor/HistoricalColor-ECCV2012-DecadeDatabase.tar > HistoricalColor-ECCV2012-DecadeDatabase.tar\")\n",
        "    os.system(\"tar -xf HistoricalColor-ECCV2012-DecadeDatabase.tar\")\n",
        "    print(\"Dataset downloaded and extracted.\")"
      ],
      "metadata": {
        "id": "55TbEXpupF8f"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare_data(data_path='HistoricalColor-ECCV2012'):\n",
        "    \"\"\"Load and prepare the dataset.\"\"\"\n",
        "    all_jpg_paths = [filename for filename in Path(data_path).glob('**/**/*.jpg')]\n",
        "    print(f'Number of images found: {len(all_jpg_paths)}')\n",
        "\n",
        "    class_label_mapping = {'1930s': 0, '1940s': 1, '1950s': 2, '1960s': 3, '1970s': 4}\n",
        "\n",
        "    df = pd.DataFrame(all_jpg_paths, columns=['paths'])\n",
        "    df['year'] = df['paths'].apply(lambda x: os.path.basename(os.path.dirname(x)))\n",
        "    df['labels'] = df['year'].map(class_label_mapping)\n",
        "\n",
        "    feature_data = extract_image_features(df)\n",
        "    return feature_data, class_label_mapping"
      ],
      "metadata": {
        "id": "mbTNExfAAUAJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_image_features(df):\n",
        "    \"\"\"Extract features from all images.\"\"\"\n",
        "    print(\"Extracting features from images...\")\n",
        "\n",
        "    features = {\n",
        "        'brightness': [], 'contrast': [], 'saturation': [], 'edge_intensity': [],\n",
        "        'hist_bins': [[] for _ in range(10)],\n",
        "        'color_stats': [[] for _ in range(6)],\n",
        "        'valid_indices': []\n",
        "    }\n",
        "\n",
        "    for idx, img_path in enumerate(df['paths']):\n",
        "        try:\n",
        "            with Image.open(img_path).convert('RGB') as image:\n",
        "                img_array = np.array(image)\n",
        "                gray_array = np.array(image.convert(\"L\"))\n",
        "\n",
        "                # Basic features\n",
        "                features['brightness'].append(np.mean(gray_array))\n",
        "                features['contrast'].append(np.std(gray_array))\n",
        "\n",
        "                # Color stats\n",
        "                for i in range(3):\n",
        "                    features['color_stats'][i*2].append(np.mean(img_array[:,:,i]))\n",
        "                    features['color_stats'][i*2+1].append(np.std(img_array[:,:,i]))\n",
        "\n",
        "                # Saturation\n",
        "                r, g, b = img_array[:,:,0]/255.0, img_array[:,:,1]/255.0, img_array[:,:,2]/255.0\n",
        "                max_rgb = np.maximum(np.maximum(r, g), b)\n",
        "                min_rgb = np.minimum(np.minimum(r, g), b)\n",
        "                diff = max_rgb - min_rgb\n",
        "                sat = np.mean(np.where(max_rgb > 0, diff / max_rgb, 0))\n",
        "                features['saturation'].append(sat)\n",
        "\n",
        "                # Histogram features\n",
        "                hist, _ = np.histogram(gray_array, bins=10, range=(0, 256))\n",
        "                hist = hist / (hist.sum() or 1)\n",
        "                for i in range(10):\n",
        "                    features['hist_bins'][i].append(hist[i])\n",
        "\n",
        "                # Edge detection\n",
        "                h, w = gray_array.shape\n",
        "                if h > 2 and w > 2:\n",
        "                    dx = np.abs(gray_array[1:, :] - gray_array[:-1, :]).mean()\n",
        "                    dy = np.abs(gray_array[:, 1:] - gray_array[:, :-1]).mean()\n",
        "                    features['edge_intensity'].append((dx + dy) / 2)\n",
        "                else:\n",
        "                    features['edge_intensity'].append(0)\n",
        "\n",
        "                features['valid_indices'].append(idx)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to process {img_path}: {e}\")\n",
        "\n",
        "    # Create DataFrame with valid images\n",
        "    df_valid = df.iloc[features['valid_indices']].copy()\n",
        "\n",
        "    # Add extracted features\n",
        "    df_valid['brightness'] = features['brightness']\n",
        "    df_valid['contrast'] = features['contrast']\n",
        "    df_valid['saturation'] = features['saturation']\n",
        "    df_valid['edge_intensity'] = features['edge_intensity']\n",
        "\n",
        "    for i in range(10):\n",
        "        df_valid[f'hist_bin_{i}'] = features['hist_bins'][i]\n",
        "\n",
        "    channel_names = ['r_mean', 'r_std', 'g_mean', 'g_std', 'b_mean', 'b_std']\n",
        "    for i, name in enumerate(channel_names):\n",
        "        df_valid[name] = features['color_stats'][i]\n",
        "\n",
        "    print(f\"Successfully processed {len(df_valid)} out of {len(df)} images\")\n",
        "    return df_valid"
      ],
      "metadata": {
        "id": "B8mse08xBQYm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset and Transforms\n",
        "def get_transforms():\n",
        "    \"\"\"Create data transforms for training and validation.\"\"\"\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    return train_transform, val_transform\n",
        "\n",
        "\n",
        "class HistoricalColorDataset(Dataset):\n",
        "    \"\"\"Dataset class for historical color images.\"\"\"\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        self.indices = self.dataframe.index.tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        actual_idx = self.indices[idx]\n",
        "        img_path = self.dataframe.iloc[idx]['paths']\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            label = self.dataframe.iloc[idx]['labels']\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label, actual_idx\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            return torch.zeros(3, 224, 224), self.dataframe.iloc[idx]['labels'], actual_idx"
      ],
      "metadata": {
        "id": "mOyRX7dzBUci"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Extraction\n",
        "def extract_combined_features(dataset, device, batch_size=32):\n",
        "    \"\"\"Extract both handcrafted and deep features from images.\"\"\"\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    # Load pre-trained model for feature extraction\n",
        "    feature_model = models.efficientnet_b0(weights='DEFAULT').to(device)\n",
        "    feature_model.eval()\n",
        "    feature_extractor = nn.Sequential(*list(feature_model.children())[:-1])\n",
        "\n",
        "    for batch_images, batch_labels, batch_indices in loader:\n",
        "        batch_images = batch_images.to(device)\n",
        "        valid_mask = ~torch.all(batch_images == 0, dim=(1, 2, 3))\n",
        "\n",
        "        # Extract deep features\n",
        "        with torch.no_grad():\n",
        "            deep_features = feature_extractor(batch_images).squeeze(-1).squeeze(-1).cpu().numpy()\n",
        "\n",
        "        for i, (deep_feat, label, actual_idx) in enumerate(zip(deep_features, batch_labels, batch_indices)):\n",
        "            if not valid_mask[i]:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Get handcrafted features\n",
        "                row_idx = dataset.dataset.dataframe.index.get_loc(actual_idx.item())\n",
        "                row = dataset.dataset.dataframe.iloc[row_idx]\n",
        "\n",
        "                # Combine handcrafted and deep features\n",
        "                basic_features = [\n",
        "                    row['brightness'], row['contrast'],\n",
        "                    row['saturation'], row['edge_intensity']\n",
        "                ]\n",
        "\n",
        "                hist_features = [row[f'hist_bin_{i}'] for i in range(10)]\n",
        "\n",
        "                color_features = [\n",
        "                    row['r_mean'], row['r_std'],\n",
        "                    row['g_mean'], row['g_std'],\n",
        "                    row['b_mean'], row['b_std']\n",
        "                ]\n",
        "\n",
        "                # Use only first 50 deep features\n",
        "                deep_feat_selected = deep_feat[:50]\n",
        "\n",
        "                combined = np.concatenate([\n",
        "                    basic_features, hist_features, color_features, deep_feat_selected\n",
        "                ])\n",
        "\n",
        "                features.append(combined)\n",
        "                labels.append(label.item())\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting features: {e}\")\n",
        "\n",
        "    return np.array(features), np.array(labels)"
      ],
      "metadata": {
        "id": "e1GOnXEhB5jK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN Model Training and Evaluation\n",
        "def train_evaluate_knn_model(train_dataset, val_dataset, test_dataset, device):\n",
        "    \"\"\"Train and evaluate a KNN model.\"\"\"\n",
        "    print(\"Extracting and processing features...\")\n",
        "\n",
        "    X_train, y_train = extract_combined_features(train_dataset, device)\n",
        "    X_val, y_val = extract_combined_features(val_dataset, device)\n",
        "    X_test, y_test = extract_combined_features(test_dataset, device)\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Apply PCA\n",
        "    n_components = min(75, X_train_scaled.shape[0] - 1, X_train_scaled.shape[1])\n",
        "    pca = PCA(n_components=n_components)\n",
        "    X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "    X_val_pca = pca.transform(X_val_scaled)\n",
        "    X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "    print(f\"PCA reduced features from {X_train_scaled.shape[1]} to {X_train_pca.shape[1]}\")\n",
        "\n",
        "    # Find best k using validation set\n",
        "    best_k = 1\n",
        "    best_val_acc = 0\n",
        "\n",
        "    print(\"Finding optimal k for KNN...\")\n",
        "    for k in range(1, 21, 2):  # Try odd k values from 1 to 19\n",
        "        knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
        "        knn.fit(X_train_pca, y_train)\n",
        "        val_pred = knn.predict(X_val_pca)\n",
        "        val_acc = accuracy_score(y_val, val_pred)\n",
        "        print(f\"k={k}, validation accuracy: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_k = k\n",
        "\n",
        "    print(f\"Best k: {best_k} with validation accuracy: {best_val_acc:.4f}\")\n",
        "\n",
        "    # Train final KNN model with best k\n",
        "    print(f\"Training final KNN model with k={best_k}...\")\n",
        "    knn = KNeighborsClassifier(n_neighbors=best_k, weights='distance')\n",
        "    knn.fit(X_train_pca, y_train)\n",
        "\n",
        "    # Evaluate on test set\n",
        "    test_pred = knn.predict(X_test_pca)\n",
        "    test_acc = accuracy_score(y_test, test_pred)\n",
        "    mae = mean_absolute_error(y_test, test_pred)\n",
        "    cm = confusion_matrix(y_test, test_pred)\n",
        "\n",
        "    print(\"KNN Results:\")\n",
        "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"MAE: {mae:.2f}\")\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(\"KNN Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "    return test_acc, mae"
      ],
      "metadata": {
        "id": "9aMt5n4OB_mu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model Definition\n",
        "class EnhancedCNN(nn.Module):\n",
        "    \"\"\"CNN model with EfficientNet backbone.\"\"\"\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(EnhancedCNN, self).__init__()\n",
        "\n",
        "        # Load pre-trained EfficientNet\n",
        "        self.backbone = models.efficientnet_b0(weights='DEFAULT')\n",
        "        in_features = self.backbone.classifier[1].in_features\n",
        "        self.backbone.classifier = nn.Identity()\n",
        "\n",
        "        # New classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(in_features, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        # Freeze early layers\n",
        "        for name, param in self.backbone.named_parameters():\n",
        "            if 'features.0.' in name or 'features.1.' in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        return self.classifier(features)\n"
      ],
      "metadata": {
        "id": "XtZDUF2ICPve"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Training and Evaluation\n",
        "def train_evaluate_cnn(train_dataset, val_dataset, test_dataset, device):\n",
        "    \"\"\"Train and evaluate CNN model.\"\"\"\n",
        "    batch_size = 32\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    model = EnhancedCNN().to(device)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=3\n",
        "    )\n",
        "\n",
        "    # Training\n",
        "    num_epochs = 20\n",
        "    best_val_acc = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    print(f\"\\nStarting CNN training for {num_epochs} epochs...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for images, labels, _ in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels, _ in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss: {avg_train_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict().copy()\n",
        "\n",
        "    # Save best model\n",
        "    if best_model_state:\n",
        "        torch.save(best_model_state, 'best_model.pth')\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    # Test the model\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels, _ in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_total += labels.size(0)\n",
        "            test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    test_acc = test_correct / test_total\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "    print(f\"Test Accuracy: {test_acc:.4f}, MAE: {mae:.2f}\")\n",
        "\n",
        "    return test_acc, mae, best_val_acc"
      ],
      "metadata": {
        "id": "wAqUMriCCbiv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Execution\n",
        "def main():\n",
        "    df, class_mapping = prepare_data()\n",
        "    train_transform, val_test_transform = get_transforms()\n",
        "    full_dataset = HistoricalColorDataset(df, transform=train_transform)\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    train_size = int(0.7 * len(full_dataset))\n",
        "    val_size = int(0.15 * len(full_dataset))\n",
        "    test_size = len(full_dataset) - train_size - val_size\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(\n",
        "        full_dataset, [train_size, val_size, test_size]\n",
        "    )\n",
        "\n",
        "    train_dataset.dataset.transform = train_transform\n",
        "    val_dataset.dataset.transform = val_test_transform\n",
        "    test_dataset.dataset.transform = val_test_transform\n",
        "\n",
        "    # Train and evaluate KNN model\n",
        "    print(\"\\nTraining KNN Model\")\n",
        "    knn_acc, knn_mae = train_evaluate_knn_model(\n",
        "        train_dataset, val_dataset, test_dataset, device\n",
        "    )\n",
        "\n",
        "    # Train and evaluate CNN\n",
        "    print(\"\\nTraining CNN Model\")\n",
        "    cnn_acc, cnn_mae, cnn_val_acc = train_evaluate_cnn(\n",
        "        train_dataset, val_dataset, test_dataset, device\n",
        "    )\n",
        "\n",
        "    # Compare model performance\n",
        "    print(\"\\nModel Comparison\")\n",
        "    print(f\"KNN - Test Accuracy: {knn_acc:.4f}, MAE: {knn_mae:.2f}\")\n",
        "    print(f\"CNN - Test Accuracy: {cnn_acc:.4f}, MAE: {cnn_mae:.2f}\")\n",
        "\n",
        "    if knn_acc >= 0.65 or cnn_acc >= 0.65:\n",
        "        print(\"\\Achieved\")\n",
        "    else:\n",
        "        print(\"\\nTarget accuracy not reached.\")\n"
      ],
      "metadata": {
        "id": "QXXww4QhChLV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bNKZYUBQCKNH",
        "outputId": "8e4a7eb6-ec92-467d-c0d4-1efacc3f3f90"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images found: 1326\n",
            "Extracting features from images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-9fb46f0c50c2>:32: RuntimeWarning: invalid value encountered in divide\n",
            "  sat = np.mean(np.where(max_rgb > 0, diff / max_rgb, 0))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to process HistoricalColor-ECCV2012/data/imgs/decade_database/1940s/._decade_e2cd1d87080d2525125f3bc6d320e302.jpg: cannot identify image file 'HistoricalColor-ECCV2012/data/imgs/decade_database/1940s/._decade_e2cd1d87080d2525125f3bc6d320e302.jpg'\n",
            "Successfully processed 1325 out of 1326 images\n",
            "\n",
            "===== Training KNN Model =====\n",
            "Extracting and processing features...\n",
            "PCA reduced features from 70 to 70\n",
            "Finding optimal k for KNN...\n",
            "k=1, validation accuracy: 0.3990\n",
            "k=3, validation accuracy: 0.3838\n",
            "k=5, validation accuracy: 0.3586\n",
            "k=7, validation accuracy: 0.3737\n",
            "k=9, validation accuracy: 0.3535\n",
            "k=11, validation accuracy: 0.3434\n",
            "k=13, validation accuracy: 0.3131\n",
            "k=15, validation accuracy: 0.3384\n",
            "k=17, validation accuracy: 0.3384\n",
            "k=19, validation accuracy: 0.3434\n",
            "Best k: 1 with validation accuracy: 0.3990\n",
            "Training final KNN model with k=1...\n",
            "KNN Results:\n",
            "Test Accuracy: 0.3900\n",
            "MAE: 0.99\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Training CNN Model =====\n",
            "\n",
            "Starting CNN training for 20 epochs...\n",
            "Epoch 1/20: Train Loss: 1.4762, Val Acc: 0.3788\n",
            "Epoch 2/20: Train Loss: 1.1995, Val Acc: 0.4343\n",
            "Epoch 3/20: Train Loss: 0.9806, Val Acc: 0.5101\n",
            "Epoch 4/20: Train Loss: 0.7800, Val Acc: 0.4848\n",
            "Epoch 5/20: Train Loss: 0.6483, Val Acc: 0.4596\n",
            "Epoch 6/20: Train Loss: 0.5886, Val Acc: 0.4949\n",
            "Epoch 7/20: Train Loss: 0.4004, Val Acc: 0.5253\n",
            "Epoch 8/20: Train Loss: 0.4006, Val Acc: 0.5051\n",
            "Epoch 9/20: Train Loss: 0.2461, Val Acc: 0.4848\n",
            "Epoch 10/20: Train Loss: 0.2224, Val Acc: 0.5960\n",
            "Epoch 11/20: Train Loss: 0.3154, Val Acc: 0.4899\n",
            "Epoch 12/20: Train Loss: 0.2359, Val Acc: 0.5657\n",
            "Epoch 13/20: Train Loss: 0.1780, Val Acc: 0.5505\n",
            "Epoch 14/20: Train Loss: 0.2040, Val Acc: 0.5404\n",
            "Epoch 15/20: Train Loss: 0.1760, Val Acc: 0.5303\n",
            "Epoch 16/20: Train Loss: 0.0744, Val Acc: 0.5606\n",
            "Epoch 17/20: Train Loss: 0.0451, Val Acc: 0.5354\n",
            "Epoch 18/20: Train Loss: 0.0436, Val Acc: 0.5556\n",
            "Epoch 19/20: Train Loss: 0.0376, Val Acc: 0.5354\n",
            "Epoch 20/20: Train Loss: 0.0540, Val Acc: 0.5606\n",
            "Test Accuracy: 0.5900, MAE: 0.67\n",
            "\n",
            "===== Model Comparison =====\n",
            "KNN - Test Accuracy: 0.3900, MAE: 0.99\n",
            "CNN - Test Accuracy: 0.5900, MAE: 0.67\n",
            "\n",
            "Target accuracy of 65% not reached. Further optimization may be needed.\n"
          ]
        }
      ]
    }
  ]
}